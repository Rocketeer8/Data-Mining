{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Table of Content**"
      ],
      "metadata": {
        "id": "c4VU4OQEL3qF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression**:\n",
        "\n",
        "[Problem we are trying to solve](#section-a1)\n",
        "\n",
        "[Check data type and visualize data](#section-a2)\n",
        "\n",
        "[Data Exploratory using Clustering](#section-a3)\n",
        "\n",
        "[Select Optimal Features](#section-a4)\n",
        "\n",
        "[Reduce Data Dimension](#section-a5)\n",
        "\n",
        "[Algorithm - Decision Tree (Regression)](#section-a6)\n",
        "\n",
        "[Algorithm - Linear Regression](#section-a7)\n",
        "\n",
        "[Algorithm - KNN (Regression)](#section-a8)\n",
        "\n",
        "[Algorithm - Random Forest (Regression)](#section-a9)\n",
        "\n",
        "[Conclusion and Findings](#section-a10)\n",
        "\n",
        "\n",
        "\n",
        "**Classification**:\n",
        "\n",
        "[Problem we are trying to solve](#section-b1)\n",
        "\n",
        "[Check data type and visualize data](#section-b2)\n",
        "\n",
        "[Data Exploratory using Clustering](#section-b3)\n",
        "\n",
        "[Select Optimal Features](#section-b4)\n",
        "\n",
        "[Reduce Data Dimension](#section-b5)\n",
        "\n",
        "[Algorithm - Decision Tree (Classification)](#section-b6)\n",
        "\n",
        "[Algorithm - KNN (Classification)](#section-b7)\n",
        "\n",
        "[Algorithm - Logistic Regression](#section-b8)\n",
        "\n",
        "[Algorithm - Random Forest (Classification)](#section-b9)\n",
        "\n",
        "[Conclusion and Findings](#section-b10)"
      ],
      "metadata": {
        "id": "2S186-XyL8DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression**"
      ],
      "metadata": {
        "id": "otoLZrypVfGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-a1\"></a> **Problem: Determine the best algorithm that accurately predict the percetage of hospitalized patient with COVID given data (features such as previous day COVID admission, hospital beds used, etc).**"
      ],
      "metadata": {
        "id": "CGnKAtvVOAnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2eA8B5viSNWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check data type and visualize data** <a name=\"section-a2\"></a>"
      ],
      "metadata": {
        "id": "bY6st5BpO_nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn import metrics, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import decomposition\n",
        "\n",
        "pd.set_option('display.max_columns', 10)\n",
        "pd.set_option('display.max_rows', 30)\n",
        "pd.set_option('display.width', 10000)\n",
        "\n",
        "data = pd.read_csv('/COVID-19_Reported_Patient_Impact_and_Hospital_Capacity_by_State.csv')\n",
        "\n",
        "print(data.info())\n",
        "print(data.describe())\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gyFLoGEOBEV",
        "outputId": "67c7d87c-91a8-4501-eb9a-7235f2a40fd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 54 entries, 0 to 53\n",
            "Columns: 134 entries, state to total_staffed_pediatric_icu_beds_coverage\n",
            "dtypes: float64(41), int64(92), object(1)\n",
            "memory usage: 56.7+ KB\n",
            "None\n",
            "       critical_staffing_shortage_today_yes  critical_staffing_shortage_today_no  critical_staffing_shortage_today_not_reported  critical_staffing_shortage_anticipated_within_week_yes  critical_staffing_shortage_anticipated_within_week_no  ...  staffed_icu_pediatric_patients_confirmed_covid_coverage  staffed_pediatric_icu_bed_occupancy  staffed_pediatric_icu_bed_occupancy_coverage  total_staffed_pediatric_icu_beds  total_staffed_pediatric_icu_beds_coverage\n",
            "count                             54.000000                            54.000000                                      54.000000                                          54.000000                                               54.000000      ...                                          54.000000                                  54.000000                                     54.000000                         54.000000                                  54.000000\n",
            "mean                               2.388889                            17.648148                                      75.407407                                           6.148148                                               58.777778      ...                                          93.166667                                 111.740741                                     93.166667                        168.222222                                  93.148148\n",
            "std                                4.759961                            26.142684                                      70.871800                                           7.953657                                               50.346223      ...                                          80.642175                                 170.736605                                     80.642175                        248.683148                                  80.642329\n",
            "min                                0.000000                             0.000000                                       1.000000                                           0.000000                                                0.000000      ...                                           1.000000                                   0.000000                                      1.000000                          0.000000                                   1.000000\n",
            "25%                                0.000000                             2.000000                                      31.250000                                           1.000000                                               18.000000      ...                                          44.250000                                  14.250000                                     44.250000                         30.250000                                  44.250000\n",
            "50%                                1.000000                             6.500000                                      53.500000                                           2.500000                                               50.500000      ...                                          86.000000                                  53.500000                                     86.000000                         89.000000                                  86.000000\n",
            "75%                                2.000000                            22.500000                                      96.500000                                           8.000000                                               84.000000      ...                                         122.750000                                 115.000000                                    122.750000                        178.000000                                 122.750000\n",
            "max                               26.000000                           110.000000                                     432.000000                                          37.000000                                              248.000000      ...                                         459.000000                                 837.000000                                    459.000000                       1294.000000                                 459.000000\n",
            "\n",
            "[8 rows x 133 columns]\n",
            "   state  critical_staffing_shortage_today_yes  critical_staffing_shortage_today_no  critical_staffing_shortage_today_not_reported  critical_staffing_shortage_anticipated_within_week_yes  ...  staffed_icu_pediatric_patients_confirmed_covid_coverage  staffed_pediatric_icu_bed_occupancy  staffed_pediatric_icu_bed_occupancy_coverage  total_staffed_pediatric_icu_beds  total_staffed_pediatric_icu_beds_coverage\n",
            "0     AK                                     1                                    6                                             11                                                  1       ...                                                 18                                          5                                            18                                 6                                         18\n",
            "1     CA                                    10                                  102                                            241                                                 37       ...                                                345                                        837                                           345                              1294                                        345\n",
            "2     FL                                     3                                   41                                            171                                                  8       ...                                                209                                        695                                           209                               980                                        209\n",
            "3     SC                                    17                                    6                                             39                                                 20       ...                                                 61                                         54                                            61                                95                                         61\n",
            "4     MN                                     0                                    0                                            128                                                  6       ...                                                127                                         89                                           127                               118                                        127\n",
            "..   ...                                   ...                                  ...                                            ...                                                ...       ...                                                ...                                        ...                                           ...                               ...                                        ...\n",
            "49    WI                                     9                                   73                                             52                                                  8       ...                                                131                                         69                                           131                                93                                        131\n",
            "50    LA                                     3                                   21                                            121                                                  2       ...                                                142                                        142                                           142                               215                                        142\n",
            "51    AZ                                     0                                   11                                             78                                                  0       ...                                                 86                                        181                                            86                               297                                         86\n",
            "52    VA                                     9                                   31                                             53                                                 11       ...                                                 90                                        120                                            90                               184                                         90\n",
            "53    IL                                     2                                   50                                            121                                                  2       ...                                                168                                        354                                           168                               525                                        168\n",
            "\n",
            "[54 rows x 134 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0X7MM_6vSPUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Exploratory using Clustering**:<a name=\"section-a3\"></a>\n",
        "\n",
        "After data visualization, do some data exloration using Hierarchical Clustering using states as labels and see if we can spot any patterns"
      ],
      "metadata": {
        "id": "MfJEVC-pQIif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "QATpeZC0IMsB",
        "outputId": "b23447f4-75d9-4bab-a797-061b59540558"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "state = list(data['state'])\n",
        "\n",
        "data = data.iloc[: , 1:]\n",
        "data = data.fillna(0)\n",
        "\n",
        "mergings = linkage(data, method='complete')\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "dendrogram(mergings,\n",
        "           p = 6,\n",
        "           truncate_mode = 'level',\n",
        "           labels = state,\n",
        "leaf_rotation=90,\n",
        "leaf_font_size=10,\n",
        ")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion from clustering:** States like CA and FL, and TX and NY appears to be similar to each other in terms of Covid hospitalization.\n",
        "\n",
        "Others states that are similar includes AS and VI, AK and VT"
      ],
      "metadata": {
        "id": "A3KUzSZxQ0j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YV6DV1DQN4KN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select Optimal Features**<a name=\"section-a4\"></a>\n",
        "\n",
        "Given we have 49 features, and given the target variable is percentage of hospitalized patient with COVID in each state, we want to find number of optimal features out of all 49 features\n",
        "\n",
        "Since feature selection for LogReg only work with discrete dataset, we want to apply discretization to our target variable first\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b6AiOcX9DLQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# discretization of the target variable\n",
        "y = data['percent_of_inpatients_with_covid'] * 100\n",
        "y_discrete = np.digitize(y,[0,1,2,3,4,5,6,7,8,9,10])\n",
        "\n",
        "# drop the target feature and select the first 49 columns\n",
        "data = data.drop(columns=['percent_of_inpatients_with_covid'])\n",
        "X = data.iloc[: , 0:49]\n",
        "\n",
        "logit=LogisticRegression(multi_class='ovr',solver='liblinear', max_iter=1000)\n",
        "\n",
        "rfecv = RFECV(estimator=logit, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
        "rfecv.fit(X, y_discrete)\n",
        "\n",
        "print(f\"Optimal number of features : {rfecv.n_features_}\")\n",
        "print(\"Features rankings:\", rfecv.ranking_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1Fv-cutDPG6",
        "outputId": "e3553c91-2ccd-434f-b30c-708d476f9b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of features : 40\n",
            "Features rankings: [ 1  1  1  1  1  1  1  1  2  6  1  7  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  5  3  4  1  1  9 10  1  1\n",
            "  8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimal feature selection conclusion**: According to the print statements above, 40 out of 49 features are optimal."
      ],
      "metadata": {
        "id": "S3nntR52Pv4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "avIlxd5MSRlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reduce Data Dimension:**<a name=\"section-a5\"></a>\n",
        "\n",
        "Now that we know the optimal number of features is 40 out of 49 features, reduce dimension to n = 40"
      ],
      "metadata": {
        "id": "abXck-X3E86Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the original data set\",X.shape)\n",
        "\n",
        "pca = decomposition.PCA(n_components=40)\n",
        "pca.fit(X)\n",
        "X_reduced = pca.transform(X)\n",
        "print(\"Shape of the new data set\",X_reduced.shape)\n",
        "\n",
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5HXxCZNFBDq",
        "outputId": "bb615745-698a-462d-e997-36b649e13a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the original data set (54, 49)\n",
            "Shape of the new data set (54, 40)\n",
            "    critical_staffing_shortage_today_yes  critical_staffing_shortage_today_no  critical_staffing_shortage_today_not_reported  critical_staffing_shortage_anticipated_within_week_yes  critical_staffing_shortage_anticipated_within_week_no  ...  percent_of_inpatients_with_covid_denominator  inpatient_bed_covid_utilization  inpatient_bed_covid_utilization_coverage  inpatient_bed_covid_utilization_numerator  inpatient_bed_covid_utilization_denominator\n",
            "0                                      1                                    6                                             11                                                  1                                                      15      ...                                         592.0                         0.016993                                      10.0                                       13.0                                        765.0\n",
            "1                                     10                                  102                                            241                                                 37                                                     248      ...                                       24933.0                         0.024654                                     166.0                                      797.0                                      32327.0\n",
            "2                                      3                                   41                                            171                                                  8                                                     129      ...                                       21489.0                         0.018129                                      96.0                                      553.0                                      30503.0\n",
            "3                                     17                                    6                                             39                                                 20                                                      33      ...                                        5702.0                         0.019324                                      44.0                                      148.0                                       7659.0\n",
            "4                                      0                                    0                                            128                                                  6                                                      81      ...                                         107.0                         0.003546                                      11.0                                        1.0                                        282.0\n",
            "..                                   ...                                  ...                                            ...                                                ...                                                     ...      ...                                           ...                              ...                                       ...                                        ...                                          ...\n",
            "49                                     9                                   73                                             52                                                  8                                                      88      ...                                        1073.0                         0.012000                                      20.0                                       21.0                                       1750.0\n",
            "50                                     3                                   21                                            121                                                  2                                                     128      ...                                        2297.0                         0.016740                                      22.0                                       57.0                                       3405.0\n",
            "51                                     0                                   11                                             78                                                  0                                                      60      ...                                        7298.0                         0.018110                                      49.0                                      174.0                                       9608.0\n",
            "52                                     9                                   31                                             53                                                 11                                                      49      ...                                        8036.0                         0.010462                                      57.0                                      125.0                                      11948.0\n",
            "53                                     2                                   50                                            121                                                  2                                                     137      ...                                        7954.0                         0.009653                                      71.0                                      115.0                                      11913.0\n",
            "\n",
            "[54 rows x 49 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "O91BRYifG95Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply all regression methods for both original features and reduced features, and compare the result**"
      ],
      "metadata": {
        "id": "4J6i59M0HQxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree (regression)**<a name=\"section-a6\"></a>\n",
        "\n",
        "Apply decision tree (regerssion) on both the original X and reduced X and compare error rates"
      ],
      "metadata": {
        "id": "1_OND6aW-SIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=5)\n",
        "\n",
        "clf = tree.DecisionTreeRegressor()\n",
        "\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"y prediction: \", y_pred)\n",
        "print(\"y actual: \", list(y_test))\n",
        "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE: \", metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "clf.fit(X_train2, y_train2)\n",
        "y_pred2 = clf.predict(X_test2)\n",
        "print(\"y prediction: \", y_pred2)\n",
        "print(\"y actual: \", list(y_test2))\n",
        "print(\"X_reduced MAE: \", metrics.mean_absolute_error(y_test2, y_pred2))\n",
        "print(\"X_reduced MSE: \", metrics.mean_squared_error(y_test2, y_pred2))\n",
        "print(\"X_reduced RMSE: \", np.sqrt(metrics.mean_squared_error(y_test2, y_pred2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2ctaOBp-Slc",
        "outputId": "ede59f0e-2317-42a9-87d1-a1634928680d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X original\n",
            "-------------------\n",
            "y prediction:  [1.4046823 1.8046358 0.6547836 0.        0.8207934 3.1965668 1.2970169\n",
            " 0.        0.6036217 3.1350196 0.8207934 0.6036217 0.5802708 2.1661932]\n",
            "y actual:  [1.4458134, 1.7132505, 0.9060023, 0.4056795, 0.8974359, 2.5734097, 1.0485197, 0.27777779999999996, 0.650524, 4.0931546, 0.9345794, 0.9225092, 0.7972857999999999, 2.1671827]\n",
            "MAE:  0.2622288928571429\n",
            "MSE:  0.13234253041559793\n",
            "RMSE:  0.3637891290508801\n",
            "\n",
            "X_reduced\n",
            "-------------------\n",
            "y prediction:  [0.78125   3.1350196 2.1959459 2.1959459 0.280112  1.2263158 4.1076115\n",
            " 1.2263158 3.1845799 0.78125   9.9337748 1.3842746 1.7132505 1.2263158]\n",
            "y actual:  [0.0, 0.8207934, 1.0282776, 0.8849558000000001, 0.4056795, 2.3842149, 1.4458134, 1.1491301, 2.6527649, 1.5594542, 2.5734097, 2.5955804999999996, 1.2970169, 0.650524]\n",
            "X_reduced MAE:  1.4621643285714285\n",
            "X_reduced MSE:  5.323658215370439\n",
            "X_reduced RMSE:  2.3073054014088465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Conclusion**: X original (MSE: 0.1323) performs better than X reduced (MSE: 5.3237) for decision tree\n",
        "\n"
      ],
      "metadata": {
        "id": "eOO7VYTsACKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "owSG93WeG8XH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**<a name=\"section-a7\"></a>\n",
        "\n",
        "Apply linear regerssion on both the original X and reduced X and compare error rates"
      ],
      "metadata": {
        "id": "8HeG8JILB1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regr = LinearRegression()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=54)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=29)\n",
        "\n",
        "#print(X_train)\n",
        "#X_train = X_train.values.reshape(-1, 1)\n",
        "\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "regr.fit(X_train, y_train)\n",
        "#print('Coefficients: \\n', regr.coef_)\n",
        "#print('Intercept: \\n', regr.intercept_)\n",
        "y_pred = regr.predict(X_test)\n",
        "print(\"y prediction: \", y_pred)\n",
        "print(\"y actual:\", list(y_test))\n",
        "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE: \", metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "regr.fit(X_train2, y_train2)\n",
        "#print('Coefficients: \\n', regr.coef_)\n",
        "#print('Intercept: \\n', regr.intercept_)\n",
        "y_pred2 = regr.predict(X_test2)\n",
        "print(\"y prediction: \", y_pred2)\n",
        "print(\"y actual:\", list(y_test2))\n",
        "print(\"X_reduced MAE: \", metrics.mean_absolute_error(y_test2, y_pred2))\n",
        "print(\"X_reduced MSE: \", metrics.mean_squared_error(y_test2, y_pred2))\n",
        "print(\"X_reduced RMSE: \", np.sqrt(metrics.mean_squared_error(y_test2, y_pred2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKq9Xb9kCYRy",
        "outputId": "46ff86f3-b8c0-4e84-ab14-2b90ac2c642a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X original\n",
            "-------------------\n",
            "y prediction:  [ 1.47977677 -5.11671021  0.58461891  1.69356697  3.79253299  0.88606438\n",
            "  0.82722214  1.57186861  1.13886408  0.48451727 -0.09902136  3.40747696\n",
            "  0.70959366 -0.82098398]\n",
            "y actual [1.4046823, 2.3842149, 1.4458134, 3.1845799, 0.8207934, 0.27777779999999996, 0.9225092, 1.5238095, 1.0485197, 0.8849558000000001, 0.0, 2.4814976, 0.6036217, 0.78125]\n",
            "MAE:  1.2053992078463491\n",
            "MSE:  5.147219292808846\n",
            "RMSE:  2.268748397863643\n",
            "\n",
            "X reduced\n",
            "-------------------\n",
            "y prediction:  [2.53608512e+00 2.22671295e+00 9.25461383e+07 2.00594940e+00\n",
            " 1.03273241e+00 1.28518780e+00 3.66085730e+00 8.35181165e-01\n",
            " 9.64648742e-01 5.25546729e-01 1.36883373e+00 4.88298025e+00\n",
            " 2.25242901e+00 2.14032262e+00]\n",
            "y actual [2.3424879, 1.2263158, 0.0, 0.650524, 1.4764008, 0.0, 2.4671735, 0.9060023, 1.0282776, 0.78125, 1.3096098, 3.1965668000000003, 1.0638298, 3.1845799]\n",
            "X_reduced MAE:  6610439.149971054\n",
            "X_reduced MSE:  611770550475122.1\n",
            "X_reduced RMSE:  24733995.845296048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression Conclusion**: X original (MSE: 5.14) performs much better than X reduced (MSE: very large) for linear regression as X original MSE error rate is much lower. Linear regression in general perform worst than decision tree"
      ],
      "metadata": {
        "id": "AUHnKoZgCsm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XiVAR7isG7L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN (regression)**<a name=\"section-a8\"></a>\n",
        "\n",
        "Apply KNN on both the original X and reduced X and compare error rates. Find error rate for K between 1 to 20 to see which one performs the best"
      ],
      "metadata": {
        "id": "F8dBnXodDL5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=9)\n",
        "\n",
        "#rmse_val = [] #to store rmse values for different k\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "for K in range(20):\n",
        "    K = K+1\n",
        "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
        "\n",
        "    model.fit(X_train, y_train)  #fit the model\n",
        "    y_pred=model.predict(X_test) #make prediction on test set\n",
        "    error = metrics.mean_squared_error(y_test, y_pred) #calculate rmse\n",
        "    #rmse_val.append(error) #store rmse values\n",
        "    print('MSE value for k= ' , K , 'is:', error)\n",
        "\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "for K in range(20):\n",
        "    K = K+1\n",
        "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
        "    model.fit(X_train2, y_train2)  #fit the model\n",
        "    y_pred2=model.predict(X_test2) #make prediction on test set\n",
        "    error = metrics.mean_squared_error(y_test2, y_pred2) #calculate rmse\n",
        "    #rmse_val.append(error) #store rmse values\n",
        "    print('X_reduced MSE value for k= ' , K , 'is:', error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTMcU3ggIkQh",
        "outputId": "7b0aa156-23d5-4728-d8e8-7934187f5251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X original\n",
            "-------------------\n",
            "MSE value for k=  1 is: 7.887403794204283\n",
            "MSE value for k=  2 is: 6.142704717334602\n",
            "MSE value for k=  3 is: 5.726131413014052\n",
            "MSE value for k=  4 is: 5.729782561528443\n",
            "MSE value for k=  5 is: 5.686724674366024\n",
            "MSE value for k=  6 is: 5.545855019724544\n",
            "MSE value for k=  7 is: 5.637963710662381\n",
            "MSE value for k=  8 is: 5.604338330176371\n",
            "MSE value for k=  9 is: 5.701514773253135\n",
            "MSE value for k=  10 is: 5.602002482738833\n",
            "MSE value for k=  11 is: 5.753047724203708\n",
            "MSE value for k=  12 is: 5.823654003833712\n",
            "MSE value for k=  13 is: 5.965731335588771\n",
            "MSE value for k=  14 is: 6.11642768424984\n",
            "MSE value for k=  15 is: 6.187884605127481\n",
            "MSE value for k=  16 is: 6.122423203025634\n",
            "MSE value for k=  17 is: 6.0708579478704925\n",
            "MSE value for k=  18 is: 6.058121843537757\n",
            "MSE value for k=  19 is: 6.117670317831227\n",
            "MSE value for k=  20 is: 6.20081954153935\n",
            "\n",
            "X reduced\n",
            "-------------------\n",
            "X_reduced MSE value for k=  1 is: 1.8856960446440336\n",
            "X_reduced MSE value for k=  2 is: 1.4665693445178156\n",
            "X_reduced MSE value for k=  3 is: 1.2699453677190884\n",
            "X_reduced MSE value for k=  4 is: 1.1442822397865413\n",
            "X_reduced MSE value for k=  5 is: 1.0970414108458357\n",
            "X_reduced MSE value for k=  6 is: 1.1312609200680268\n",
            "X_reduced MSE value for k=  7 is: 1.4118408323757197\n",
            "X_reduced MSE value for k=  8 is: 1.394379793281777\n",
            "X_reduced MSE value for k=  9 is: 1.449337889800653\n",
            "X_reduced MSE value for k=  10 is: 1.3287677483902958\n",
            "X_reduced MSE value for k=  11 is: 1.3519340159944566\n",
            "X_reduced MSE value for k=  12 is: 1.1800182971793556\n",
            "X_reduced MSE value for k=  13 is: 0.9296640235711304\n",
            "X_reduced MSE value for k=  14 is: 0.9080549131317665\n",
            "X_reduced MSE value for k=  15 is: 1.0093089720379125\n",
            "X_reduced MSE value for k=  16 is: 1.0224256074713078\n",
            "X_reduced MSE value for k=  17 is: 0.9187521310084316\n",
            "X_reduced MSE value for k=  18 is: 0.9063203734501801\n",
            "X_reduced MSE value for k=  19 is: 0.9294522107206559\n",
            "X_reduced MSE value for k=  20 is: 0.9768232692721852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN Conclusion**: X reduced performs better than X original in general for KNN as the error rate for X reduced is lower.\n",
        "\n",
        "For X original: K = 6 is the best option (MSE: 5.55)\n",
        "\n",
        "For X rediced: K = 18 is the best option (MSE: 0.91)\n",
        "\n",
        "KNN performed better than linear regression but worst than decision tree"
      ],
      "metadata": {
        "id": "HgyTiUu-D0QA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EwDjrQ2NG4q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest (regression)**<a name=\"section-a9\"></a>\n",
        "\n",
        "Apply Random Forest on both the original X and reduced X and compare error rates."
      ],
      "metadata": {
        "id": "ajQOh5LEGHkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=12)\n",
        "\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "rfc = RandomForestRegressor(n_estimators=600)\n",
        "rfc.fit(X_train,y_train)\n",
        "y_pred = rfc.predict(X_test)\n",
        "# print MAE. MSE, and RMSE\n",
        "print(\"y prediction: \", y_pred)\n",
        "print(\"y actual: \", list(y_test))\n",
        "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE: \", metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "rfc = RandomForestRegressor(n_estimators=600)\n",
        "rfc.fit(X_train2,y_train2)\n",
        "y_pred2 = rfc.predict(X_test2)\n",
        "# print MAE. MSE, and RMSE for X_reduced\n",
        "print(\"y prediction: \", y_pred)\n",
        "print(\"y actual: \", list(y_test))\n",
        "print(\"X_reduced MAE: \", metrics.mean_absolute_error(y_test2, y_pred2))\n",
        "print(\"X_reduced MSE: \", metrics.mean_squared_error(y_test2, y_pred2))\n",
        "print(\"X_reduced RMSE: \", np.sqrt(metrics.mean_squared_error(y_test2, y_pred2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHIVNQEsGHvg",
        "outputId": "44247a33-19e4-4df5-fbf8-c1bc9bd3c01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X original\n",
            "-------------------\n",
            "y prediction:  [0.37976312 1.52120928 1.30881701 1.52940619 2.30780549 2.56373217\n",
            " 1.10690158 3.2641008  0.5337374  0.08533147 2.55634727 0.92396997\n",
            " 1.50797343 1.42403152]\n",
            "y actual:  [0.28011199999999997, 1.8046357999999998, 0.0, 1.9571295, 1.4764008, 2.1671827, 1.0282776, 2.5734097, 0.27777779999999996, 0.0, 2.1661932, 0.8207934, 0.8849558000000001, 1.5555002]\n",
            "MAE:  0.40757108673809495\n",
            "MSE:  0.2827877604933337\n",
            "RMSE:  0.5317779240372185\n",
            "\n",
            "X reduced\n",
            "-------------------\n",
            "y prediction:  [0.37976312 1.52120928 1.30881701 1.52940619 2.30780549 2.56373217\n",
            " 1.10690158 3.2641008  0.5337374  0.08533147 2.55634727 0.92396997\n",
            " 1.50797343 1.42403152]\n",
            "y actual:  [0.28011199999999997, 1.8046357999999998, 0.0, 1.9571295, 1.4764008, 2.1671827, 1.0282776, 2.5734097, 0.27777779999999996, 0.0, 2.1661932, 0.8207934, 0.8849558000000001, 1.5555002]\n",
            "X_reduced MAE:  1.22535963313095\n",
            "X_reduced MSE:  2.683669514450389\n",
            "X_reduced RMSE:  1.6381909273495532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random forest Conclusion**: X original (MSE: 0.2828) performs better than X reduced (MSE: 2.6837) for random forest."
      ],
      "metadata": {
        "id": "aEZRUz78HD57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "E6048ehuSbI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All regression methods conclusion:** <a name=\"section-a10\"></a>\n",
        "\n",
        "Regression algorithms for the selected data ranked from best to worst according to the conclusions above:\n",
        "\n",
        "*   **X original:**\n",
        "Decision Tree (MSE: 0.1323) > Random Forest (MSE: 0.2828) > Linear Regression (MSE: 5.14) > KNN (MSE: 5.55)\n",
        "*   **X reduced:**\n",
        "KNN (MSE: 0.91) > Random Forest (MSE: 2.6837) > Decision Tree (MSE: 5.3237) > Linear Regression (MSE: very large)\n",
        "\n",
        "**Findings:**\n",
        "For X original, Decision Tree and Random Forest seems to perform very well while Linear Regression and KNN performed poorly. This makes sense as there are some outliers in the data (ex: some state has abnormally high staff shortage in hospital) and Decision Tree and Random Forest are not sensetive to outliers."
      ],
      "metadata": {
        "id": "ofbueK5GMoU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "B4O736d7Scyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6pIGTDPwPJEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification**"
      ],
      "metadata": {
        "id": "xsWBLgoJe-bO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b1\"></a>**Problem: Determine the best algorithm that accurately predict if an insurance claim for an individual is santioned or not  (based on features such as insurance agency name, agency net sales, insurance plan of the individual etc).**"
      ],
      "metadata": {
        "id": "c3Pb5fS2C44u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b2\"></a>**Check data type and visualize data**"
      ],
      "metadata": {
        "id": "laT-7bLVEg_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.read_csv('/insurance_dataset.csv')\n",
        "\n",
        "agency = list(data2[\"Agency\"].iloc[:100])\n",
        "# fill NaN fields with 0\n",
        "data2 = data2.fillna(0)\n",
        "data2 = data2.drop(columns=['Gender'])\n",
        "\n",
        "\n",
        "print(data2.info())\n",
        "print(data2.describe())\n",
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFM7kEY_Ehrx",
        "outputId": "678793fd-9eca-4d1f-951e-4898041703ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10537 entries, 0 to 10536\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   ID                    10537 non-null  int64  \n",
            " 1   Age                   10537 non-null  int64  \n",
            " 2   Agency                10537 non-null  object \n",
            " 3   Agency Type           10537 non-null  object \n",
            " 4   Commision (in value)  10537 non-null  float64\n",
            " 5   Destination           10537 non-null  object \n",
            " 6   Distribution Channel  10537 non-null  object \n",
            " 7   Duration              10537 non-null  int64  \n",
            " 8   Net Sales             10537 non-null  float64\n",
            " 9   Product Name          10537 non-null  object \n",
            " 10  Claim                 10537 non-null  int64  \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 905.6+ KB\n",
            "None\n",
            "                 ID           Age  Commision (in value)      Duration     Net Sales         Claim\n",
            "count  10537.000000  10537.000000          10537.000000  10537.000000  10537.000000  10537.000000\n",
            "mean   32819.611654     39.589447             12.793249     61.090158     51.391107      0.199013\n",
            "std    18158.084102     13.962649             23.777388    105.559453     64.475120      0.399277\n",
            "min        7.000000      0.000000              0.000000     -1.000000   -389.000000      0.000000\n",
            "25%    17367.000000     33.000000              0.000000     10.000000     20.000000      0.000000\n",
            "50%    33395.000000     36.000000              0.270000     24.000000     29.700000      0.000000\n",
            "75%    48784.000000     43.000000             13.630000     60.000000     59.400000      0.000000\n",
            "max    63317.000000    118.000000            210.210000   4844.000000    599.000000      1.000000\n",
            "          ID  Age Agency    Agency Type  Commision (in value)  ... Distribution Channel Duration  Net Sales                     Product Name Claim\n",
            "0      45341   28    C2B       Airlines                 28.13  ...               Online       34      112.5                      Silver Plan     1\n",
            "1      12958   37    JZI       Airlines                 12.95  ...               Online       53       37.0                       Basic Plan     0\n",
            "2      18233   27    EPX  Travel Agency                  0.00  ...               Online       28       13.0                Cancellation Plan     0\n",
            "3      31742   36    EPX  Travel Agency                  0.00  ...               Online        1       34.0                Cancellation Plan     0\n",
            "4      14381   26    CWT  Travel Agency                 23.76  ...               Online       33       39.6  Rental Vehicle Excess Insurance     0\n",
            "...      ...  ...    ...            ...                   ...  ...                  ...      ...        ...                              ...   ...\n",
            "10532   9441   36    EPX  Travel Agency                  0.00  ...               Online       22       25.0         1 way Comprehensive Plan     0\n",
            "10533  46089   58    C2B       Airlines                 54.00  ...               Online      368      216.0               Annual Silver Plan     1\n",
            "10534  30389   36    EPX  Travel Agency                  0.00  ...               Online       15       15.0                Cancellation Plan     0\n",
            "10535   1932   34    JZI       Airlines                  7.70  ...               Online       25       22.0                       Basic Plan     0\n",
            "10536    691   28    EPX  Travel Agency                  0.00  ...               Online       90       10.0                Cancellation Plan     0\n",
            "\n",
            "[10537 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KV5NDDy8RS0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b3\"></a>**Data Exploratory using Clustering**:\n",
        "\n",
        "After data visualization, do some data exloration using Hierarchical Clustering and agency name as labels and see if we can spot any patterns.\n",
        "\n",
        "Hierarchical Clustering only work with numeric data, so apply LabelEncoder() to transform categorical data to numeric."
      ],
      "metadata": {
        "id": "S3QcP7fIEpLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "data2['Agency'] = label_encoder.fit_transform(data2['Agency'])\n",
        "data2['Agency Type'] = label_encoder.fit_transform(data2['Agency Type'])\n",
        "data2['Destination'] = label_encoder.fit_transform(data2['Destination'])\n",
        "data2['Distribution Channel'] = label_encoder.fit_transform(data2['Distribution Channel'])\n",
        "data2['Product Name'] = label_encoder.fit_transform(data2['Product Name'])\n",
        "\n",
        "\n",
        "\n",
        "print(data2)\n",
        "mergings = linkage(data2.head(100), method='complete')\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "dendrogram(mergings,\n",
        "           p = 5,\n",
        "           truncate_mode = 'level',\n",
        "           labels = agency,\n",
        "leaf_rotation=90,\n",
        "leaf_font_size=9,\n",
        ")\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "YrLnwwK1e-Ie",
        "outputId": "607c8e18-0826-44ff-92c2-d3294e692960"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ID  Age  Agency  Agency Type  Commision (in value)  ...  Distribution Channel  Duration  Net Sales  Product Name  Claim\n",
            "0      45341   28       2            0                 28.13  ...                     1        34      112.5            17      1\n",
            "1      12958   37       9            0                 12.95  ...                     1        53       37.0             8      0\n",
            "2      18233   27       7            1                  0.00  ...                     1        28       13.0            10      0\n",
            "3      31742   36       7            1                  0.00  ...                     1         1       34.0            10      0\n",
            "4      14381   26       6            1                 23.76  ...                     1        33       39.6            16      0\n",
            "...      ...  ...     ...          ...                   ...  ...                   ...       ...        ...           ...    ...\n",
            "10532   9441   36       7            1                  0.00  ...                     1        22       25.0             0      0\n",
            "10533  46089   58       2            0                 54.00  ...                     1       368      216.0             4      1\n",
            "10534  30389   36       7            1                  0.00  ...                     1        15       15.0            10      0\n",
            "10535   1932   34       9            0                  7.70  ...                     1        25       22.0             8      0\n",
            "10536    691   28       7            1                  0.00  ...                     1        90       10.0            10      0\n",
            "\n",
            "[10537 rows x 11 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion from clustering:** claim submission for agency C2B is similar to other C2B submissions(which make sense). On top of that, it seems data for C2B claim submission is also similar to EPX submission as they are grouped closely in several instance (small distance between them compare to other agencies)"
      ],
      "metadata": {
        "id": "CJuM4rg3Iwrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Q8QdGX6JP50i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b4\"></a>**Select Optimal Features**\n",
        "\n",
        "Given we have 10 features, and given the target variable is whether the claim submissions are sanctioned or not (1 = sanctioned, 0 = not sanctioned), we want to find number of optimal features out of all 10 features."
      ],
      "metadata": {
        "id": "N5lpRmmnzZnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data2.drop(columns=['Claim'])\n",
        "y = data2['Claim']\n",
        "\n",
        "logit=LogisticRegression(multi_class='ovr',solver='liblinear', max_iter=1000)\n",
        "\n",
        "rfecv = RFECV(estimator=logit, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "print(f\"Optimal number of features : {rfecv.n_features_}\")\n",
        "print(\"listing column names and their ranking\")\n",
        "print(list(X.columns.values))\n",
        "print(rfecv.ranking_)\n",
        "#print(X.columns[0], X.columns[1],X.columns[30],X.columns[33], X.columns[37])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "watuB0I9zZzq",
        "outputId": "36a5b6cd-8b1b-4e43-95e5-da6263b71fa7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of features : 9\n",
            "listing column names and their ranking\n",
            "['ID', 'Age', 'Agency', 'Agency Type', 'Commision (in value)', 'Destination', 'Distribution Channel', 'Duration', 'Net Sales', 'Product Name']\n",
            "[2 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimal feature selection conclusion**: According to the print statements above, besides feature \"ID\", every other feature is optimal"
      ],
      "metadata": {
        "id": "hKKV0j52PgGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "01a3sLWMRP8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b5\"></a>**Reduce Data Dimension:**\n",
        "\n",
        "Now that we know the optimal number of features is 9 out of 10 features, reduce dimension to n = 9"
      ],
      "metadata": {
        "id": "JQXLgLcc3OLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the original data set\",X.shape)\n",
        "\n",
        "pca = decomposition.PCA(n_components=9)\n",
        "pca.fit(X)\n",
        "X_reduced = pca.transform(X)\n",
        "print(\"Shape of the new data set\",X_reduced.shape)\n",
        "\n",
        "print(X_reduced)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QYYCPpJ3Ofx",
        "outputId": "c2008e78-54a5-4846-b0eb-72d56aa4d9ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the original data set (10537, 10)\n",
            "Shape of the new data set (10537, 9)\n",
            "[[-1.25214041e+04  6.94903888e-01 -6.62689603e+01 ...  8.65136249e+00\n",
            "  -2.66931134e+00 -1.58979702e-01]\n",
            " [ 1.98616154e+04 -5.80722375e+00  4.31938512e+00 ... -1.47772662e+00\n",
            "   2.60146863e+00 -9.16397072e-01]\n",
            " [ 1.45866296e+04 -4.14461552e+01  1.69472912e+01 ...  2.11669228e+00\n",
            "   1.23763606e+00  2.60567442e-01]\n",
            " ...\n",
            " [ 2.43063432e+03 -5.71109810e+01  1.20448400e+01 ...  1.04409617e+00\n",
            "   8.91024028e-01  2.87956733e-01]\n",
            " [ 3.08876277e+04 -3.43787486e+01  3.85013609e+00 ... -1.07036743e+00\n",
            "   1.96276368e+00 -1.00272027e+00]\n",
            " [ 3.21286183e+04  1.70789795e+01  4.60131416e+01 ...  2.91315944e+00\n",
            "  -4.55087652e-01  1.51465425e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ns0M6ksKR5PR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply all classification methods for both original features and reduced features, and compare the result**"
      ],
      "metadata": {
        "id": "sECjv-ZKR6Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b6\"></a>**Decision Tree (classification)**\n",
        "\n",
        "Apply decision tree (classification) on both the original X and reduced X and compare error rates"
      ],
      "metadata": {
        "id": "jwtvdNcY3N8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=5)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy score: \", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Recall/Sensitivity: \", metrics.recall_score(y_test, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "clf.fit(X_train2, y_train2)\n",
        "y_pred2 = clf.predict(X_test2)\n",
        "print(\"X_reduced Accuracy score: \", metrics.accuracy_score(y_test2, y_pred2))\n",
        "print(\"X_reduced Recall/Sensitivity: \", metrics.recall_score(y_test2, y_pred2))\n",
        "print(\"X_reduced Precision: \", metrics.precision_score(y_test2, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2E74KC_1knQ",
        "outputId": "246c408d-d701-4340-c588-cc9f0e318d12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X original\n",
            "-------------------\n",
            "Accuracy score:  0.9009487666034156\n",
            "Recall/Sensitivity:  0.8693181818181818\n",
            "Precision:  0.7050691244239631\n",
            "\n",
            "X reduced\n",
            "-------------------\n",
            "X_reduced Accuracy score:  0.8941176470588236\n",
            "X_reduced Recall/Sensitivity:  0.8662900188323918\n",
            "X_reduced Precision:  0.688622754491018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Conclusion**: X original (Accuracy: 0.9039) performs sightly better than X reduced (Accuracy: 0.8934) for decision tree but the difference is not significant.\n"
      ],
      "metadata": {
        "id": "g0YW59bPtV9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CLnTspMJ1wLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b7\"></a>**KNN (classification)**\n",
        "\n",
        "Apply KNN on both the original X and reduced X and compare error rates. Find error rate for K between 1 to 20 to see which one performs the best"
      ],
      "metadata": {
        "id": "2BG7X5pY4aIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=12)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=18)\n",
        "\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "for K in range(20):\n",
        "    K = K+1\n",
        "    model = neighbors.KNeighborsClassifier(n_neighbors = K)\n",
        "    model.fit(X_train, y_train)  #fit the model\n",
        "    y_pred=model.predict(X_test) #make prediction on test set\n",
        "    # find accuracy score\n",
        "    print(\"Accuracy score: \", metrics.accuracy_score(y_test, y_pred), \"for k = \", K)\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "for K in range(20):\n",
        "    K = K+1\n",
        "    model = neighbors.KNeighborsClassifier(n_neighbors = K)\n",
        "    model.fit(X_train2, y_train2)  #fit the model\n",
        "    y_pred2=model.predict(X_test2) #make prediction on test set\n",
        "    # find accuracy score\n",
        "    print(\"X reduced Accuracy score: \", metrics.accuracy_score(y_test2, y_pred2), \"for k = \", K)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmA5p_Ad4acO",
        "outputId": "0941eb0e-668a-4214-8909-6c136c38dacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X original\n",
            "-------------------\n",
            "Accuracy score:  0.8971537001897533 for k =  1\n",
            "Accuracy score:  0.8755218216318785 for k =  2\n",
            "Accuracy score:  0.8451612903225807 for k =  3\n",
            "Accuracy score:  0.8368121442125237 for k =  4\n",
            "Accuracy score:  0.8242884250474384 for k =  5\n",
            "Accuracy score:  0.8178368121442126 for k =  6\n",
            "Accuracy score:  0.8144212523719165 for k =  7\n",
            "Accuracy score:  0.8174573055028463 for k =  8\n",
            "Accuracy score:  0.8178368121442126 for k =  9\n",
            "Accuracy score:  0.8159392789373814 for k =  10\n",
            "Accuracy score:  0.8144212523719165 for k =  11\n",
            "Accuracy score:  0.8140417457305503 for k =  12\n",
            "Accuracy score:  0.8106261859582543 for k =  13\n",
            "Accuracy score:  0.8098671726755218 for k =  14\n",
            "Accuracy score:  0.8064516129032258 for k =  15\n",
            "Accuracy score:  0.8068311195445921 for k =  16\n",
            "Accuracy score:  0.8 for k =  17\n",
            "Accuracy score:  0.8022770398481973 for k =  18\n",
            "Accuracy score:  0.8037950664136623 for k =  19\n",
            "Accuracy score:  0.7992409867172675 for k =  20\n",
            "\n",
            "X reduced\n",
            "-------------------\n",
            "X reduced Accuracy score:  0.8990512333965844 for k =  1\n",
            "X reduced Accuracy score:  0.8785578747628083 for k =  2\n",
            "X reduced Accuracy score:  0.8489563567362429 for k =  3\n",
            "X reduced Accuracy score:  0.8432637571157495 for k =  4\n",
            "X reduced Accuracy score:  0.8330170777988615 for k =  5\n",
            "X reduced Accuracy score:  0.8299810246679317 for k =  6\n",
            "X reduced Accuracy score:  0.8178368121442126 for k =  7\n",
            "X reduced Accuracy score:  0.8269449715370019 for k =  8\n",
            "X reduced Accuracy score:  0.8166982922201138 for k =  9\n",
            "X reduced Accuracy score:  0.8216318785578748 for k =  10\n",
            "X reduced Accuracy score:  0.8178368121442126 for k =  11\n",
            "X reduced Accuracy score:  0.822011385199241 for k =  12\n",
            "X reduced Accuracy score:  0.8155597722960152 for k =  13\n",
            "X reduced Accuracy score:  0.8148007590132827 for k =  14\n",
            "X reduced Accuracy score:  0.8163187855787476 for k =  15\n",
            "X reduced Accuracy score:  0.8189753320683112 for k =  16\n",
            "X reduced Accuracy score:  0.818595825426945 for k =  17\n",
            "X reduced Accuracy score:  0.8140417457305503 for k =  18\n",
            "X reduced Accuracy score:  0.8129032258064516 for k =  19\n",
            "X reduced Accuracy score:  0.8113851992409867 for k =  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN conclusion**: We found that k = 1 is the optimal for both X and X_reduced and X original's accuracy. Also accuracy for both dataset is very similar (~0.9 or 90%)"
      ],
      "metadata": {
        "id": "mUI3TpNO6EeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wyzAHfDm1uU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b8\"></a>**Logistic Regression**\n",
        "\n",
        "Apply Logistic Regression with stratified cross validation and compare error rates"
      ],
      "metadata": {
        "id": "JX3QTbgM6WWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logit=LogisticRegression(multi_class='ovr',solver='liblinear', max_iter=1000)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=13)\n",
        "\n",
        "rfecv = RFECV(estimator=logit, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "rfecv.fit(X_train, y_train)\n",
        "y_pred=rfecv.predict(X_test)\n",
        "print(\"Accuracy score: \", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Recall/Sensitivity: \", metrics.recall_score(y_test, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "rfecv.fit(X_train2, y_train2)\n",
        "y_pred2=rfecv.predict(X_test2)\n",
        "print(\"X_reduced Accuracy score: \", metrics.accuracy_score(y_test2, y_pred2))\n",
        "print(\"X_reduced Recall/Sensitivity: \", metrics.recall_score(y_test2, y_pred2))\n",
        "print(\"X_reduced Precision: \", metrics.precision_score(y_test2, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLnRflj_6Wuq",
        "outputId": "c72dd752-fced-4ff8-8b6a-dc1cb4a64f05"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X original\n",
            "-------------------\n",
            "Accuracy score:  0.8250474383301708\n",
            "Recall/Sensitivity:  0.22285714285714286\n",
            "Precision:  0.6882352941176471\n",
            "\n",
            "X reduced\n",
            "-------------------\n",
            "X_reduced Accuracy score:  0.8333965844402277\n",
            "X_reduced Recall/Sensitivity:  0.30038022813688214\n",
            "X_reduced Precision:  0.6899563318777293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Conclusion**: X reduced (Accuracy: 0.8334) performs sightly better than X original (Accuracy: 0.8250) for logistic regression but the difference is not significant.\n"
      ],
      "metadata": {
        "id": "nYJ9eWMFyH4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_WsOOSaT1s2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b9\"></a>**Random Forest (classification)**\n",
        "\n",
        "Apply Random Forest on both the original X and reduced X and compare error rates."
      ],
      "metadata": {
        "id": "CPnjQoIn98iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reduced, y, random_state=12)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=300, criterion='entropy')\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "print(\"X original\")\n",
        "print(\"-------------------\")\n",
        "y_pred = rfc.predict(X_test)\n",
        "# print Accuracy. Sensitivity, and Precision\n",
        "print(\"Accuracy score: \", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Recall/Sensitivity: \", metrics.recall_score(y_test, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=300, criterion='entropy')\n",
        "rfc.fit(X_train2,y_train2)\n",
        "\n",
        "print(\"\\nX reduced\")\n",
        "print(\"-------------------\")\n",
        "y_pred2 = rfc.predict(X_test2)\n",
        "# print Accuracy. Sensitivity, and Precision\n",
        "print(\"X_reduced Accuracy score: \", metrics.accuracy_score(y_test2, y_pred2))\n",
        "print(\"X_reduced Recall/Sensitivity: \", metrics.recall_score(y_test2, y_pred2))\n",
        "print(\"X_reduced Precision: \", metrics.precision_score(y_test2, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-tCMAxh98zL",
        "outputId": "65b3078f-c3ed-46e5-c7c7-01fe65fbd4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X original\n",
            "-------------------\n",
            "Accuracy score:  0.9499051233396585\n",
            "Recall/Sensitivity:  0.8986866791744841\n",
            "Precision:  0.8599640933572711\n",
            "\n",
            "X reduced\n",
            "-------------------\n",
            "X_reduced Accuracy score:  0.932068311195446\n",
            "X_reduced Recall/Sensitivity:  0.8505535055350554\n",
            "X_reduced Precision:  0.8246869409660107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Conclusion**: X original (Accuracy: 0.95) performs sightly better than X reduced (Accuracy: 0.932) for random forest."
      ],
      "metadata": {
        "id": "m7FZ-E6uyi2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Jum-XrqRzHIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-b10\"></a>**All classification methods conclusion:**\n",
        "\n",
        "Classification algorithms for the selected data ranked from best to worst according to the conclusions above:\n",
        "\n",
        "\n",
        "*   **X original:**\n",
        "Random Forest (Accuracy: 0.95) > Decision Tree (Accuracy: 0.9039) > KNN (Accuracy: 0.8971) > Logistic Regression (Accuracy: 0.825)\n",
        "\n",
        "*   **X reduced:**\n",
        "Random Forest (Accuracy: 0.932) > KNN (Accuracy: 0.899) > Decision Tree (Accuracy: 0.893) > Logistic Regression (Accuracy: 0.8334)\n",
        "\n",
        "**Findings:** For both X original and X reduced, Logistic Regression does not do as well as the other 3 algorithms. It's the only algorithm that rely the linearity of the data for accurate prediction. But since the claim approval (our target variable) are judge on a case by case basis by the agency, the outcome is sometimes unpredictable regardless of the features provided. Therefore the chance of non-linear data is high and it makes sense Logistic regression didn't do as well.\n"
      ],
      "metadata": {
        "id": "Ie140GJazGYQ"
      }
    }
  ]
}